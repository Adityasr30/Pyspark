{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a909bbf",
   "metadata": {},
   "source": [
    "## Loading data in PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080d18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.context import SparkContext\n",
    "sc = SparkContext(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "889a6022",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1 = sc.parallelize([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e39f5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = sc.textFile(\"test.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0268c",
   "metadata": {},
   "source": [
    "## Lambda Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3cbfad",
   "metadata": {},
   "source": [
    "Syntax:\n",
    "\n",
    "lambda arguments: expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8975fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "double = lambda x:x*2\n",
    "print(double(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beda6797",
   "metadata": {},
   "source": [
    "Difference between def and lambda:\n",
    "\n",
    "def is used for named functions with more complex logic, while lambda is used for simple, anonymous functions that are often used for short-term tasks or as arguments to higher-order functions. Also, def can contain multiple expressions and a return statement, whereas, lambda contains only a single expression. Anonymous means does not having any name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4896449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "def cube(x):\n",
    "    return x ** 3\n",
    "\n",
    "g = lambda x: x ** 3\n",
    "\n",
    "print(g(10))\n",
    "print(cube(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5abd59",
   "metadata": {},
   "source": [
    "## Map function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9b04e0",
   "metadata": {},
   "source": [
    "map() function takes a function and a list and returns a new list which contains items returnzed by that function for each item.\n",
    "\n",
    "General syntax of map():\n",
    "\n",
    "map(function, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d09b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5, 6]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [1,2,3,4]\n",
    "list(map(lambda x: x+2, items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ae2e09",
   "metadata": {},
   "source": [
    "## Filter function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baea354a",
   "metadata": {},
   "source": [
    "Filter function takes a function and a list and returns a new list for which the function evaluates as true.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "filter(function, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0145d34e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [1,2,3,4]\n",
    "list(filter(lambda x: (x%2 != 0), items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a14cb87",
   "metadata": {},
   "source": [
    "## RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1026182e",
   "metadata": {},
   "source": [
    "Resilient Distributed Datasets\n",
    "\n",
    "- Resilient: Ability to withstand failures\n",
    "- Distributed: Spanning across multiple machines\n",
    "- Datasets: Collection of partitioned data e.g, Arrays, Tables, Tuples etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ee81a",
   "metadata": {},
   "source": [
    "## Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e131c7e0",
   "metadata": {},
   "source": [
    "Partition is a logical division of a large distributed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efba8230",
   "metadata": {},
   "outputs": [],
   "source": [
    "numRDD = sc.parallelize(range(10), numSlices = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20aa7840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41714f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileRDD = sc.textFile(r\"C:\\Users\\aditya.rambhad\\Downloads\\spark notes.txt\", minPartitions = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523dc06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615287de",
   "metadata": {},
   "source": [
    "## PySpark Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99cdb3f",
   "metadata": {},
   "source": [
    "- Transformations create new RDDs\n",
    "- Actions perform computation on the RDDs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a6da79",
   "metadata": {},
   "source": [
    "## Basic RDD Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0508192",
   "metadata": {},
   "source": [
    "- map()\n",
    "- filter()\n",
    "- flatMap()\n",
    "- union()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfbe85c",
   "metadata": {},
   "source": [
    "### map() Transformation\n",
    "\n",
    "- Applies a funciton to all elements in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e9f5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD = sc.parallelize([1,2,3,4])\n",
    "RDD_map = RDD.map(lambda x: x * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc34d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: [1,4,9,16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c7cad",
   "metadata": {},
   "source": [
    "### filter() Transformation\n",
    "\n",
    "- Returns a new RDD with only the elements that pass the condition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e92f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD = sc.parallelize([1,2,3,4])\n",
    "RDD_filter = RDD.filter(lambda x: x > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81dc17c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: [3,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c267c479",
   "metadata": {},
   "source": [
    "### flatMap() Transformation\n",
    "\n",
    "- Returns multiple values for each element in the original RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88d570c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD = sc.parallelize([\"hello world\", \"how are you\"])\n",
    "RDD_flatmap = RDD.flatMap(lambda x: x.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49f2ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: [\"hello\",\"world\",\"how\",\"are\",\"you\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e7b964",
   "metadata": {},
   "source": [
    "## RDD Actions\n",
    "\n",
    "- Operation return a value after running a compution on the RDD.\n",
    "- Basic RDD Actions\n",
    "  - collect()\n",
    "  - take(N)\n",
    "  - first()\n",
    "  - count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d908896",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD = sc.parallelize([1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe605e8",
   "metadata": {},
   "source": [
    "### collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6049099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDD.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7e9fd5",
   "metadata": {},
   "source": [
    "### take()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c34ec30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD.take(2)\n",
    "\n",
    "# Output: [1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf9e5a5",
   "metadata": {},
   "source": [
    "### first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f00bc42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD.first()\n",
    "\n",
    "# Output: [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca9f764",
   "metadata": {},
   "source": [
    "### count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0894750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD.count()\n",
    "\n",
    "# Output: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7622236",
   "metadata": {},
   "source": [
    "## Pair RDDs\n",
    "\n",
    "- Real life datasets are usually key/value pairs.\n",
    "- Pair RDD: Key is the identifier and value is data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b1b668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tuple = [('Sam', 23), ('Mary', 34), ('Peter', 25)]\n",
    "pairRDD_tuple = sc.parallelize(my_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa6a9087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sam', 23), ('Mary', 34), ('Peter', 25)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairRDD_tuple.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80094576",
   "metadata": {},
   "source": [
    "## Pair RDDs Transformations\n",
    "\n",
    "- reduceByKey()\n",
    "- groupByKey()\n",
    "- sortByKey(): Return an RDD sorted by the key\n",
    "- join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46085b66",
   "metadata": {},
   "source": [
    "### reduceByKey() transformation\n",
    "\n",
    "- Combine values with the same key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e098023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularRDD = sc.parallelize([(\"Messi\", 23), (\"Ronaldo\", 34), (\"Neymar\", 22), (\"Messi\", 24)]) \n",
    "pairRDD_reducebykey = regularRDD.reduceByKey(lambda x,y : x + y) \n",
    "pairRDD_reducebykey.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce1864ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: [('Neymar', 22), ('Ronaldo', 34), ('Messi', 47)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bccba57",
   "metadata": {},
   "source": [
    "### groupByKey() transformation\n",
    "\n",
    "- Group values with the same key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a613b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = [(\"US\", \"JFK\"),(\"UK\", \"LHR\"),(\"FR\", \"CDG\"),(\"US\", \"SFO\")]\n",
    "regularRDD = sc.parallelize(airports) \n",
    "pairRDD_group = regularRDD.groupByKey().collect() \n",
    "for cont, air in pairRDD_group:\n",
    "    print(cont, list(air))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f417c89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: \n",
    "FR ['CDG']\n",
    "US ['JFK', 'SFO'] \n",
    "UK ['LHR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46801c90",
   "metadata": {},
   "source": [
    "### join() transformation\n",
    "\n",
    "- Join two pairRDDs based on their key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0438d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD1 = sc.parallelize([(\"Messi\", 34),(\"Ronaldo\", 32),(\"Neymar\", 24)])\n",
    "RDD2 = sc.parallelize([(\"Ronaldo\", 80),(\"Neymar\", 120),(\"Messi\", 100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0d43445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: [('Neymar', (24, 120)), ('Ronaldo', (32, 80)), ('Messi', (34, 100))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca158b",
   "metadata": {},
   "source": [
    "## Actions on pair RDDs\n",
    "\n",
    "- countByKey()\n",
    "- collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ca69f5",
   "metadata": {},
   "source": [
    "### countByKey()\n",
    "\n",
    "- Counts the number of elements for each key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3920c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize([(\"a\", 1), (\"b\", 1), (\"a\", 1)]) \n",
    "for kee, val in rdd.countByKey().items():\n",
    "    print(kee, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d207938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output:\n",
    "('a', 2)\n",
    "('b', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b8f30",
   "metadata": {},
   "source": [
    "### collectAsMap()\n",
    "\n",
    "- Returns the key-value pairs in the RDD as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e5f27dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.parallelize([(1, 2), (3, 4)]).collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c7516c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: {1: 2, 3: 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa626ff",
   "metadata": {},
   "source": [
    "## More Actions on RDDs\n",
    "\n",
    "- reduce()\n",
    "- saveAsTextFile()\n",
    "- coalesce()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3e2dd3",
   "metadata": {},
   "source": [
    "### reduce()\n",
    "\n",
    "- reduce() aciton is used for aggregating the elements of a regular RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "de378b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,3,4,6]\n",
    "RDD = sc.parallelize(x) \n",
    "RDD.reduce(lambda x, y : x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "db0d89fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output: 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d79f34",
   "metadata": {},
   "source": [
    "### saveAsTextFile()\n",
    "\n",
    "- Saves RDD into a text file inside a directory with each partition as a separate file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71c4863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD.saveAsTextFile(\"tempFile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7d8c19",
   "metadata": {},
   "source": [
    "### coalesce()\n",
    "\n",
    "- Used to save RDD as a single text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b41bdd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD.coalesce(1).saveAsTextFile(\"tempFile\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4741f800",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9b105",
   "metadata": {},
   "source": [
    "- PySpark DataFrame is an immutable distributed collection of data with named columns.\n",
    "- Designed for processing both structured (e.g relational database) and semi-structured data(e.g JSON).\n",
    "- DataFramesin PySparksupportboth SQL queries( SELECT * from table ) or expression methods ( df.select() ).\n",
    "- SparkSession: Entry point to interact with Spark DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569fe98",
   "metadata": {},
   "source": [
    "## Create DataFrame from RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "029bd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fa4c26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iphones_RDD = sc.parallelize([\n",
    "    (\"XS\", 2018, 5.65, 2.79, 6.24),\n",
    "    (\"XR\", 2018, 5.94, 2.98, 6.84),\n",
    "    (\"X10\", 2017, 5.65, 2.79, 6.13),\n",
    "    (\"8Plus\", 2017, 6.23, 3.07, 7.12)\n",
    "])\n",
    "\n",
    "names = ['Model', 'Year', 'Height', 'Width', 'Weight']\n",
    "\n",
    "iphones_df = spark.createDataFrame(iphones_RDD, schema=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e077a",
   "metadata": {},
   "source": [
    "## Create a DataFrame from reading a CSV/JSON/TXT\n",
    "\n",
    "- Two optional parameters\n",
    "  - header = True\n",
    "  - inferSchema = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4ce3cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = spark.read.csv(\"people.json\", header=True, inferSchema=True)\n",
    "\n",
    "df_json = spark.read.json(\"people.json\", header=True, inferSchema=True)\n",
    "\n",
    "df_txt = spark.read.txt(\"people.txt\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0169f6e0",
   "metadata": {},
   "source": [
    "## DataFrame operations\n",
    "\n",
    "- Transformations:\n",
    "  - select()\n",
    "  - filer()\n",
    "  - groupby()\n",
    "  - orderby()\n",
    "  - dropDuplicates()\n",
    "  - withColumnRenamed()\n",
    "- Actions:\n",
    "  - printSchema()\n",
    "  - head()\n",
    "  - show()\n",
    "  - count()\n",
    "  - columns()\n",
    "  - describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad272a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(r\"C:\\Users\\aditya.rambhad\\Downloads\\IPL - Player Performance Dataset\\IPL_Ball_by_Ball_2008_2022.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459447e0",
   "metadata": {},
   "source": [
    "### select() operation\n",
    "\n",
    "- subsets the columns in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ce64d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|     ID|\n",
      "+-------+\n",
      "|1312200|\n",
      "|1312200|\n",
      "|1312200|\n",
      "|1312200|\n",
      "|1312200|\n",
      "+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_id = df.select('ID')\n",
    "\n",
    "df_id.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3cf2d",
   "metadata": {},
   "source": [
    "### filter() operation\n",
    "\n",
    "- Filters out the rows based on a condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e3bb6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|     batter|total_run|\n",
      "+-----------+---------+\n",
      "| JC Buttler|        4|\n",
      "|YBK Jaiswal|        4|\n",
      "|YBK Jaiswal|        6|\n",
      "+-----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_runs = df.filter(df.total_run >= 4)\n",
    "\n",
    "df_runs.select('batter','total_run').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59952db3",
   "metadata": {},
   "source": [
    "### where() operation\n",
    "\n",
    "- Same as filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d2bd6522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|     batter|total_run|\n",
      "+-----------+---------+\n",
      "| JC Buttler|        4|\n",
      "|YBK Jaiswal|        4|\n",
      "|YBK Jaiswal|        6|\n",
      "+-----------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_runs = df.where(df.total_run >= 4)\n",
    "\n",
    "df_runs.select('batter','total_run').show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349c4348",
   "metadata": {},
   "source": [
    "### groupby() operation\n",
    "\n",
    "- Can be used to group a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c2b26ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|        batter|count|\n",
      "+--------------+-----+\n",
      "| Kuldeep Yadav|  130|\n",
      "|  M Theekshana|    7|\n",
      "|    KA Pollard| 2447|\n",
      "|   SS Cottrell|    2|\n",
      "|R Sanjay Yadav|    2|\n",
      "+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_group = df.groupby('')\n",
    "\n",
    "df_group.count().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1f3d4b",
   "metadata": {},
   "source": [
    "### orderby() operation\n",
    "\n",
    "- Sorts the dataframe based on one or more columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b9ee0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|        batter|count|\n",
      "+--------------+-----+\n",
      "|   RP Meredith|    1|\n",
      "|V Pratap Singh|    1|\n",
      "| Y Prithvi Raj|    1|\n",
      "|    Yash Dayal|    1|\n",
      "|      JL Denly|    1|\n",
      "+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_group.count().orderBy('count').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52cbdf",
   "metadata": {},
   "source": [
    "### dropDuplicates() operation\n",
    "\n",
    "- Removes the duplicate rows of a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f08622f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225954\n",
      "14229\n"
     ]
    }
   ],
   "source": [
    "df_dup = df.select('ID','batter').dropDuplicates()\n",
    "\n",
    "print(df.select('ID','batter').count())\n",
    "print(df_dup.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91620cb",
   "metadata": {},
   "source": [
    "### withColumnRenamed() operation\n",
    "\n",
    "- Renames a column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c49d9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|     ID|     player|\n",
      "+-------+-----------+\n",
      "|1312200|YBK Jaiswal|\n",
      "|1312200|YBK Jaiswal|\n",
      "|1312200| JC Buttler|\n",
      "|1312200|YBK Jaiswal|\n",
      "|1312200|YBK Jaiswal|\n",
      "+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_renamed = df.withColumnRenamed('batter', 'player')\n",
    "\n",
    "df_renamed.select('ID','player').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97869a88",
   "metadata": {},
   "source": [
    "### withColumn() operation\n",
    "\n",
    "- Adds a new column to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "564e0a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+-----------+--------------+\n",
      "|     ID|     batter|      upper|        splits|\n",
      "+-------+-----------+-----------+--------------+\n",
      "|1312200|YBK Jaiswal|YBK JAISWAL|[YBK, Jaiswal]|\n",
      "|1312200|YBK Jaiswal|YBK JAISWAL|[YBK, Jaiswal]|\n",
      "|1312200| JC Buttler| JC BUTTLER| [JC, Buttler]|\n",
      "|1312200|YBK Jaiswal|YBK JAISWAL|[YBK, Jaiswal]|\n",
      "|1312200|YBK Jaiswal|YBK JAISWAL|[YBK, Jaiswal]|\n",
      "+-------+-----------+-----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "df_new = df.withColumn('upper', F.upper('batter')) \\\n",
    "           .withColumn('splits', F.split('batter',' '))\n",
    "    \n",
    "df_new.select('ID','batter','upper','splits').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d76a4ea",
   "metadata": {},
   "source": [
    "### drop() operation\n",
    "\n",
    "- Removes a column from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c6b487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+\n",
      "|     ID|     batter|\n",
      "+-------+-----------+\n",
      "|1312200|YBK Jaiswal|\n",
      "|1312200|YBK Jaiswal|\n",
      "|1312200| JC Buttler|\n",
      "|1312200|YBK Jaiswal|\n",
      "|1312200|YBK Jaiswal|\n",
      "+-------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_drop = df_new.select('ID','batter','upper').drop('upper')\n",
    "\n",
    "df_drop.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc8ba21",
   "metadata": {},
   "source": [
    "### printSchema()\n",
    "\n",
    "- Prints the types of columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "173abf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- innings: integer (nullable = true)\n",
      " |-- overs: integer (nullable = true)\n",
      " |-- ballnumber: integer (nullable = true)\n",
      " |-- batter: string (nullable = true)\n",
      " |-- bowler: string (nullable = true)\n",
      " |-- non-striker: string (nullable = true)\n",
      " |-- extra_type: string (nullable = true)\n",
      " |-- batsman_run: integer (nullable = true)\n",
      " |-- extras_run: integer (nullable = true)\n",
      " |-- total_run: integer (nullable = true)\n",
      " |-- non_boundary: integer (nullable = true)\n",
      " |-- isWicketDelivery: integer (nullable = true)\n",
      " |-- player_out: string (nullable = true)\n",
      " |-- kind: string (nullable = true)\n",
      " |-- fielders_involved: string (nullable = true)\n",
      " |-- BattingTeam: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe389cdb",
   "metadata": {},
   "source": [
    "### columns\n",
    "\n",
    "- Prints the columns of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55c79812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'innings',\n",
       " 'overs',\n",
       " 'ballnumber',\n",
       " 'batter',\n",
       " 'bowler',\n",
       " 'non-striker',\n",
       " 'extra_type',\n",
       " 'batsman_run',\n",
       " 'extras_run',\n",
       " 'total_run',\n",
       " 'non_boundary',\n",
       " 'isWicketDelivery',\n",
       " 'player_out',\n",
       " 'kind',\n",
       " 'fielders_involved',\n",
       " 'BattingTeam']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c01ac3",
   "metadata": {},
   "source": [
    "### describe()\n",
    "\n",
    "- Compute summary statistics of numerical columns in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ab1c756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+------------------+--------------+-----------------+------------------+\n",
      "|summary|        batter|         total_run|        bowler|            overs|        ballnumber|\n",
      "+-------+--------------+------------------+--------------+-----------------+------------------+\n",
      "|  count|        225954|            225954|        225954|           225954|            225954|\n",
      "|   mean|          null|1.3104304415943069|          null|9.185679386069731|3.6197500376182763|\n",
      "| stddev|          null|1.6060501061067816|          null|5.681796781138258|1.8106327890386609|\n",
      "|    min|A Ashish Reddy|                 0|A Ashish Reddy|                0|                 1|\n",
      "|    max|        Z Khan|                 7|        Z Khan|               19|                10|\n",
      "+-------+--------------+------------------+--------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('batter','total_run','bowler','overs','ballnumber').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9dea6",
   "metadata": {},
   "source": [
    "### head()\n",
    "\n",
    "- Shows the first row in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb55b341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ID=1312200, innings=1, overs=0, ballnumber=1, batter='YBK Jaiswal', bowler='Mohammed Shami', non-striker='JC Buttler', extra_type='NA', batsman_run=0, extras_run=0, total_run=0, non_boundary=0, isWicketDelivery=0, player_out='NA', kind='NA', fielders_involved='NA', BattingTeam='Rajasthan Royals')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe82867",
   "metadata": {},
   "source": [
    "### explain()\n",
    "\n",
    "- Shows the physical plan of execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3efbdafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [ID#119, innings#120, overs#121, ballnumber#122, batter#123, bowler#124, non-striker#125, extra_type#126, batsman_run#127, extras_run#128, total_run#129, non_boundary#130, isWicketDelivery#131, player_out#132, kind#133, fielders_involved#134, BattingTeam#135, upper(batter#123) AS upper#3348, split(batter#123,  , -1) AS splits#3367]\n",
      "+- FileScan csv [ID#119,innings#120,overs#121,ballnumber#122,batter#123,bowler#124,non-striker#125,extra_type#126,batsman_run#127,extras_run#128,total_run#129,non_boundary#130,isWicketDelivery#131,player_out#132,kind#133,fielders_involved#134,BattingTeam#135] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/aditya.rambhad/Downloads/IPL - Player Performance Datas..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<ID:int,innings:int,overs:int,ballnumber:int,batter:string,bowler:string,non-striker:string...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5f1ee0",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "- lit()\n",
    "- substring()\n",
    "- regexp_replace()\n",
    "- broadcast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0aa98598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc0cb9",
   "metadata": {},
   "source": [
    "### lit() function\n",
    "\n",
    "- Add a literal or constant to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35865f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+---+\n",
      "|     ID|     batter|IPL|\n",
      "+-------+-----------+---+\n",
      "|1312200|YBK Jaiswal|IPL|\n",
      "|1312200|YBK Jaiswal|IPL|\n",
      "|1312200| JC Buttler|IPL|\n",
      "|1312200|YBK Jaiswal|IPL|\n",
      "|1312200|YBK Jaiswal|IPL|\n",
      "+-------+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ID','batter',F.lit('IPL')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a42c6a",
   "metadata": {},
   "source": [
    "### substring() function\n",
    "\n",
    "- Gets substring from a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2b1d603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|     batter|player|\n",
      "+-----------+------+\n",
      "|YBK Jaiswal|   YBK|\n",
      "|YBK Jaiswal|   YBK|\n",
      "| JC Buttler|   JC |\n",
      "|YBK Jaiswal|   YBK|\n",
      "|YBK Jaiswal|   YBK|\n",
      "+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('batter',F.substring('batter',0,3).alias('player')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2acd16",
   "metadata": {},
   "source": [
    "### regexp_replace() function\n",
    "\n",
    "- Replace a column value with a string for another string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "497e2974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|     batter|  Updated_batter|\n",
      "+-----------+----------------+\n",
      "|YBK Jaiswal|Yashasvi Jaiswal|\n",
      "|YBK Jaiswal|Yashasvi Jaiswal|\n",
      "| JC Buttler|      JC Buttler|\n",
      "|YBK Jaiswal|Yashasvi Jaiswal|\n",
      "|YBK Jaiswal|Yashasvi Jaiswal|\n",
      "+-----------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('batter',F.regexp_replace('batter','YBK','Yashasvi').alias('Updated_batter')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a59c65c",
   "metadata": {},
   "source": [
    "### broadcast() function\n",
    "\n",
    "- Used to broadcast smaller dataframe for join operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "080cede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = spark.read.csv(r\"C:\\Users\\aditya.rambhad\\Downloads\\IPL - Player Performance Dataset\\IPL_Ball_by_Ball_2008_2022.csv\", header=True, inferSchema=True)\n",
    "df2 = spark.read.csv(r\"C:\\Users\\aditya.rambhad\\Downloads\\IPL - Player Performance Dataset\\IPL_Matches_2008_2022.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d1e9e7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225954"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.count() #larger df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ec965e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count() #smaller df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "878aa54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import broadcast\n",
    "\n",
    "joined_df = df1.join(broadcast(df2),df1.ID == df2.ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b993a704",
   "metadata": {},
   "source": [
    "## Conditional clauses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7e24c",
   "metadata": {},
   "source": [
    "- Inline version of if / then / else\n",
    "- when()\n",
    "- otherwise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef09587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+-----------+\n",
      "|     batter|batsman_run|is_boundary|\n",
      "+-----------+-----------+-----------+\n",
      "|YBK Jaiswal|          0|         no|\n",
      "|YBK Jaiswal|          0|         no|\n",
      "| JC Buttler|          1|         no|\n",
      "|YBK Jaiswal|          0|         no|\n",
      "|YBK Jaiswal|          0|         no|\n",
      "|YBK Jaiswal|          0|         no|\n",
      "| JC Buttler|          0|         no|\n",
      "| JC Buttler|          0|         no|\n",
      "| JC Buttler|          4|        yes|\n",
      "| JC Buttler|          0|         no|\n",
      "+-----------+-----------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.batter, df.batsman_run,\n",
    "         F.when(df.batsman_run >= 4, \"yes\")\n",
    "         .otherwise('no').alias('is_boundary')).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df892aa7",
   "metadata": {},
   "source": [
    "## Interacting with DataFrames using PySpark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9ef057",
   "metadata": {},
   "source": [
    "### DataFrame API vs SQL queries\n",
    "\n",
    "- The DataFrame API provides a programmatic domain-specific language(DSL) for data\n",
    "- DataFrame transformations and actions are easier to construct programmatically\n",
    "- SQL queries can be concise and easier to understand and portable\n",
    "- The operations on DataFrames can also be done using SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d15c29fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"table1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea22f12",
   "metadata": {},
   "source": [
    "sql() method takes a SQL statement as an argument and returns the result as DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "05bc78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|     batter|total_run|\n",
      "+-----------+---------+\n",
      "|YBK Jaiswal|        0|\n",
      "|YBK Jaiswal|        1|\n",
      "| JC Buttler|        1|\n",
      "|YBK Jaiswal|        0|\n",
      "|YBK Jaiswal|        0|\n",
      "+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = spark.sql(\"Select batter, total_run from table1\")\n",
    "df2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df20664",
   "metadata": {},
   "source": [
    "### Summarizing and grouping data using SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "70ee29de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------+\n",
      "|        batter|runs_scored|\n",
      "+--------------+-----------+\n",
      "| Kuldeep Yadav|        111|\n",
      "|  M Theekshana|         11|\n",
      "|    KA Pollard|       3650|\n",
      "|   SS Cottrell|          0|\n",
      "|R Sanjay Yadav|          0|\n",
      "+--------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''Select batter, sum(total_run) as runs_scored from table1 group by batter'''\n",
    "\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3218168e",
   "metadata": {},
   "source": [
    "### Filtering columns using SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e85e59ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|     batter|total_run|\n",
      "+-----------+---------+\n",
      "| JC Buttler|        4|\n",
      "|YBK Jaiswal|        4|\n",
      "|YBK Jaiswal|        6|\n",
      "|YBK Jaiswal|        6|\n",
      "|  SV Samson|        4|\n",
      "+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = '''Select batter, total_run from table1 where total_run >= 4'''\n",
    "\n",
    "spark.sql(query).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fcc291",
   "metadata": {},
   "source": [
    "## User defined functions\n",
    "\n",
    "- Python method\n",
    "- Wrapped via the pyspark.sql.functions.udf method\n",
    "- Stored as a variable\n",
    "- Called like a normal Spark function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bc13e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "def reverseString(mystr):\n",
    "    return mystr[::-1]\n",
    "\n",
    "udfReverseString = udf(reverseString, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2d78507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_udf = df.withColumn('ReverseName', udfReverseString(df.batter))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
